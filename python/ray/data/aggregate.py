import math
from typing import TYPE_CHECKING, Any, Callable, List, Optional, Union

from bokeh.models.dom import TableRow

from ray.data._internal.planner.exchange.sort_task_spec import SortKey
from ray.data._internal.util import is_nan
from ray.data.block import AggType, Block, BlockAccessor, KeyType, T, U
from ray.util.annotations import PublicAPI

if TYPE_CHECKING:
    import pyarrow as pa


@PublicAPI
class AggregateFn:
    """Defines how to perform a custom aggregation in Ray Data.

    `AggregateFn` instances are passed to a Dataset's ``.aggregate(...)`` method to
    specify the steps required to transform and combine rows sharing the same key.
    This enables implementing custom aggregators beyond the standard
    built-in options like Sum, Min, Max, Mean, etc.

    Args:
        init: Function that creates an initial aggregator for each group. Receives a key
            (the group key) and returns the initial accumulator state (commonly 0,
            an empty list, or an empty dictionary).
        merge: Function that merges two accumulators generated by different workers
            into one accumulator.
        name: An optional display name for the aggregator. Useful for debugging.
        accumulate_row: Function that processes an individual row. It receives the current
            accumulator and a row, then returns an updated accumulator. Cannot be
            used if `accumulate_block` is provided.
        accumulate_block: Function that processes an entire block of rows at once. It receives the
            current accumulator and a block of rows, then returns an updated accumulator.
            This allows for vectorized operations. Cannot be used if `accumulate_row`
            is provided.
        finalize: Function that finishes the aggregation by transforming the final
            accumulator state into the desired output. For example, if your
            accumulator is a list of items, you may want to compute a statistic
            from the list. If not provided, the final accumulator state is returned
            as-is.

    Example:
        .. testcode::

            import ray
            from ray.data.aggregate import AggregateFn

            # A simple aggregator that counts how many rows there are per group
            count_agg = AggregateFn(
                init=lambda k: 0,
                accumulate_row=lambda counter, row: counter + 1,
                merge=lambda c1, c2: c1 + c2,
                name="custom_count"
            )
            ds = ray.data.from_items([{"group": "A"}, {"group": "B"}, {"group": "A"}])
            result = ds.groupby("group").aggregate(count_agg).take_all()
            # result: [{'group': 'A', 'custom_count': 2}, {'group': 'B', 'custom_count': 1}]
    """

    def __init__(
        self,
        init: Callable[[KeyType], AggType],
        merge: Callable[[AggType, AggType], AggType],
        name: str,
        accumulate_row: Callable[[AggType, T], AggType] = None,
        accumulate_block: Callable[[AggType, Block], AggType] = None,
        finalize: Optional[Callable[[AggType], U]] = None,
    ):
        if (accumulate_row is None and accumulate_block is None) or (
            accumulate_row is not None and accumulate_block is not None
        ):
            raise ValueError(
                "Exactly one of accumulate_row or accumulate_block must be provided."
            )
        if accumulate_block is None:

            def accumulate_block(a: AggType, block: Block) -> AggType:
                block_acc = BlockAccessor.for_block(block)
                for r in block_acc.iter_rows(public_row_format=False):
                    a = accumulate_row(a, r)
                return a

        if not isinstance(name, str):
            raise TypeError("`name` must be provided.")

        if finalize is None:
            finalize = lambda a: a  # noqa: E731

        self.init = init
        self.merge = merge
        self.name = name
        self.accumulate_block = accumulate_block
        self.finalize = finalize

    def _validate(self, schema: Optional[Union[type, "pa.lib.Schema"]]) -> None:
        """Raise an error if this cannot be applied to the given schema."""
        pass


class _AggregateOnKeyBase(AggregateFn):
    def _set_key_fn(self, on: str):
        self._key_fn = on

    def _validate(self, schema: Optional[Union[type, "pa.lib.Schema"]]) -> None:
        SortKey(self._key_fn).validate_schema(schema)


@PublicAPI
class Count(AggregateFn):
    """Defines count aggregation."""

    def __init__(self):
        super().__init__(
            init=lambda k: 0,
            accumulate_block=(
                lambda a, block: a + BlockAccessor.for_block(block).num_rows()
            ),
            merge=lambda a1, a2: a1 + a2,
            name="count()",
        )


@PublicAPI
class Sum(_AggregateOnKeyBase):
    """Defines sum aggregation."""

    def __init__(
        self,
        on: Optional[str] = None,
        ignore_nulls: bool = True,
        alias_name: Optional[str] = None,
    ):
        self._set_key_fn(on)
        if alias_name:
            self._rs_name = alias_name
        else:
            self._rs_name = f"sum({str(on)})"

        merge = _null_safe_merge(lambda a1, a2: a1 + a2)

        super().__init__(
            init=None,
            merge=merge,
            accumulate_block=(
                lambda acc, block:
                    merge(acc, BlockAccessor.for_block(block).sum(on, ignore_nulls))
            ),
            finalize=lambda a: a,
            name=(self._rs_name),
        )


@PublicAPI
class Min(_AggregateOnKeyBase):
    """Defines min aggregation."""

    def __init__(
        self,
        on: Optional[str] = None,
        ignore_nulls: bool = True,
        alias_name: Optional[str] = None,
    ):
        self._set_key_fn(on)
        if alias_name:
            self._rs_name = alias_name
        else:
            self._rs_name = f"min({str(on)})"

        merge = _null_safe_merge(min)

        super().__init__(
            init=None,
            merge=merge,
            accumulate_block=lambda acc, block: merge(acc, BlockAccessor.for_block(block).min(on, ignore_nulls)),
            finalize=lambda a: a,
            name=(self._rs_name),
        )


@PublicAPI
class Max(_AggregateOnKeyBase):
    """Defines max aggregation."""

    def __init__(
        self,
        on: Optional[str] = None,
        ignore_nulls: bool = True,
        alias_name: Optional[str] = None,
    ):
        self._set_key_fn(on)
        if alias_name:
            self._rs_name = alias_name
        else:
            self._rs_name = f"max({str(on)})"

        merge = _null_safe_merge(max)

        super().__init__(
            init=None,
            merge=merge,
            accumulate_block=lambda acc, block: merge(acc, BlockAccessor.for_block(block).max(on, ignore_nulls)),
            finalize=lambda a: a,
            name=(self._rs_name),
        )


@PublicAPI
class Mean(_AggregateOnKeyBase):
    """Defines mean aggregation."""

    def __init__(
        self,
        on: Optional[str] = None,
        ignore_nulls: bool = True,
        alias_name: Optional[str] = None,
    ):
        self._set_key_fn(on)
        if alias_name:
            self._rs_name = alias_name
        else:
            self._rs_name = f"mean({str(on)})"

        def vectorized_mean(block: Block) -> AggType:
            block_acc = BlockAccessor.for_block(block)
            count = block_acc.count(on)
            if count == 0 or count is None:
                # Empty or all null.
                return None
            sum_ = block_acc.sum(on, ignore_nulls)
            if sum_ is None:
                # ignore_nulls=False and at least one null.
                return None
            return [sum_, count]

        merge = _null_safe_merge(
            lambda a1, a2: [a1[0] + a2[0], a1[1] + a2[1]],
        )

        super().__init__(
            init=None,
            merge=merge,
            accumulate_block=lambda acc, block: merge(acc, vectorized_mean(block)),
            finalize=lambda a: a[0] / a[1],
            name=(self._rs_name),
        )


@PublicAPI
class Std(_AggregateOnKeyBase):
    """Defines standard deviation aggregation.

    Uses Welford's online method for an accumulator-style computation of the
    standard deviation. This method was chosen due to its numerical
    stability, and it being computable in a single pass.
    This may give different (but more accurate) results than NumPy, Pandas,
    and sklearn, which use a less numerically stable two-pass algorithm.
    See
    https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm
    """

    def __init__(
        self,
        on: Optional[str] = None,
        ddof: int = 1,
        ignore_nulls: bool = True,
        alias_name: Optional[str] = None,
    ):
        self._set_key_fn(on)
        if alias_name:
            self._rs_name = alias_name
        else:
            self._rs_name = f"std({str(on)})"

        def _merge(a: List[float], b: List[float]):
            # Merges two accumulations into one.
            # See
            # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm
            M2_a, mean_a, count_a = a
            M2_b, mean_b, count_b = b
            delta = mean_b - mean_a
            count = count_a + count_b
            # NOTE: We use this mean calculation since it's more numerically
            # stable than mean_a + delta * count_b / count, which actually
            # deviates from Pandas in the ~15th decimal place and causes our
            # exact comparison tests to fail.
            mean = (mean_a * count_a + mean_b * count_b) / count
            # Update the sum of squared differences.
            M2 = M2_a + M2_b + (delta**2) * count_a * count_b / count
            return [M2, mean, count]

        def vectorized_std(block: Block) -> AggType:
            block_acc = BlockAccessor.for_block(block)
            count = block_acc.count(on)
            if count == 0 or count is None:
                # Empty or all null.
                return None
            sum_ = block_acc.sum(on, ignore_nulls)
            if sum_ is None:
                # ignore_nulls=False and at least one null.
                return None
            mean = sum_ / count
            M2 = block_acc.sum_of_squared_diffs_from_mean(on, ignore_nulls, mean)
            return [M2, mean, count]

        def finalize(a: List[float]):
            # Compute the final standard deviation from the accumulated
            # sum of squared differences from current mean and the count.
            M2, mean, count = a
            if count < 2:
                return 0.0
            return math.sqrt(M2 / (count - ddof))

        merge = _null_safe_merge(_merge)

        super().__init__(
            init=None,
            merge=merge,
            accumulate_block=lambda acc, block: merge(acc, vectorized_std(block)),
            finalize=finalize,
            name=(self._rs_name),
        )


@PublicAPI
class AbsMax(_AggregateOnKeyBase):
    """Defines absolute max aggregation."""

    def __init__(
        self,
        on: Optional[str] = None,
        ignore_nulls: bool = True,
        alias_name: Optional[str] = None,
    ):
        self._set_key_fn(on)
        if alias_name:
            self._rs_name = alias_name
        else:
            self._rs_name = f"abs_max({str(on)})"

        if on is None or not isinstance(on, str):
            raise ValueError(f"Column to aggregate on has to be provided (got {on})")

        selector = lambda r: r[on]
        _null_safe_abs = lambda v: v if not _is_null(v) else None

        merge = _null_safe_merge(max)

        super().__init__(
            init=None,
            merge=merge,
            # TODO rebase onto block based impl using min_max
            accumulate_row=lambda a, r: merge(a, _null_safe_abs(selector(r))),
            finalize=lambda a: a,
            name=(self._rs_name),
        )


@PublicAPI
class Quantile(_AggregateOnKeyBase):
    """Defines Quantile aggregation."""

    def __init__(
        self,
        on: Optional[str] = None,
        q: float = 0.5,
        ignore_nulls: bool = True,
        alias_name: Optional[str] = None,
    ):
        self._set_key_fn(on)
        self._q = q
        if alias_name:
            self._rs_name = alias_name
        else:
            self._rs_name = f"quantile({str(on)})"

        def _merge(a: List[int], b: List[int]):
            if isinstance(a, List) and isinstance(b, List):
                a.extend(b)
                return a
            if isinstance(a, List) and (not isinstance(b, List)):
                if b is not None and b != "":
                    a.append(b)
                return a
            if isinstance(b, List) and (not isinstance(a, List)):
                if a is not None and a != "":
                    b.append(a)
                return b

            ls = []
            if a is not None and a != "":
                ls.append(a)
            if b is not None and b != "":
                ls.append(b)
            return ls

        def block_row_ls(block: Block) -> AggType:
            block_acc = BlockAccessor.for_block(block)
            ls = []
            for row in block_acc.iter_rows(public_row_format=False):
                ls.append(row.get(on))
            return ls

        import math

        def percentile(input_values, key: Optional[Callable[[Any], Any]] = None):
            if not input_values:
                return None

            if key is None:
                key = lambda x: x  # noqa: E731

            input_values = sorted(input_values)
            k = (len(input_values) - 1) * self._q
            f = math.floor(k)
            c = math.ceil(k)
            if f == c:
                return key(input_values[int(k)])
            d0 = key(input_values[int(f)]) * (c - k)
            d1 = key(input_values[int(c)]) * (k - f)
            return round(d0 + d1, 5)

        merge = _null_safe_merge(_merge)

        super().__init__(
            init=None,
            merge=merge,
            accumulate_block=lambda acc, block: merge(acc, block_row_ls(block)),
            finalize=percentile,
            name=(self._rs_name),
        )


@PublicAPI
class Unique(_AggregateOnKeyBase):
    """Defines unique aggregation."""

    def __init__(
        self,
        on: Optional[str] = None,
        alias_name: Optional[str] = None,
    ):
        self._set_key_fn(on)
        if alias_name:
            self._rs_name = alias_name
        else:
            self._rs_name = f"unique({str(on)})"

        def to_set(x):
            if isinstance(x, set):
                return x
            elif isinstance(x, list):
                return set(x)
            else:
                return {x}

        def block_row_unique(block: Block) -> AggType:
            import pyarrow.compute as pac

            col = BlockAccessor.for_block(block).to_arrow().column(on)
            return pac.unique(col).to_pylist()

        def _merge(a, b):
            return to_set(a) | to_set(b)

        merge = _null_safe_merge(_merge)

        super().__init__(
            init=lambda x: set(),
            merge=merge,
            accumulate_block=lambda acc, block: merge(acc, block_row_unique(block)),
            finalize=lambda x: x,
            name=(self._rs_name),
        )


def _is_null(a: Optional[AggType]) -> bool:
    return a is None or is_nan(a)


def _null_safe_merge(merge: Callable[[AggType, AggType], AggType]) -> Callable[[Optional[AggType], Optional[AggType]], AggType]:
    def _safe_merge(a: Optional[AggType], b: Optional[AggType]) -> AggType:
        a_is_null = _is_null(a)
        b_is_null = _is_null(b)

        if a_is_null and b_is_null:
            return None
        elif a_is_null:
            return b
        elif b_is_null:
            return a
        else:
            return merge(a, b)

    return _safe_merge